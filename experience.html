<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>experience</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="experience.html" class="logo"><strong>Bhavisha Narendra Chaudhari</strong></a>
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/bhavisha06/" class="icon brands fa-linkedin"><span class="label">linkedin</span></a></li>
										<li><a href="https://github.com/Bhavisha-06" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="mailto:bhavisha2705@gmail.com" class="icon solid fa-envelope"><span class="label">Gmail</span></a></li>
										<li><a href="tel:+918983328161" class="icon solid fa-phone"><span class="label">Phone number</span></a></li>									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1 style="text-decoration: underline; text-decoration-color: #f56a6a;">Work Experience</h1>
									</header>

									<hr class="major" />
									<span style="float: right; color: grey;">Jan'26 - May'26</span>
									<h2>Research Associate</h2>
									<h3 style ="float: right">Research advisor: Prof. Sukhendu Das</h3>
									<h3>Indian Institute of Technology, Madras (<a href = "https://www.cse.iitm.ac.in/~vplab/index1.html">VP Lab - IITM</a>)</h3>
									<p>Leading an extensive review of Monocular Metric Depth Estimation (MMDE), covering taxonomy, evaluation protocols, and benchmarking methodologies.
									Contributed to applied computer vision tasks such as evaluating and shortlisting depth cameras based on accuracy and trade-offs, developing a Python-based calibration tool for stereo cameras that automates chessboard corner detection and coordinate extraction for estimating intrinsic and extrinsic camera parameters, designing a stereo feature-matching algorithm to obtain sub-pixel quad correspondences on the wheel rim across two camera views for improved 3D reconstruction and geometric consistency, with correspondence validation based on y-shift and disparity (99% accuracy).
									</p>
                                    <hr class="major" />
									<span style="float: right; color: grey;">May'25 - Jul'26</span>
									<h2>Summer Research Intern</h2>
									<h3 style ="float: right">Research advisor: Prof. Sukhendu Das</h3>
									<h3>Indian Institute of Technology, Madras (<a href = "https://www.cse.iitm.ac.in/~vplab/index1.html">VP Lab - IITM</a>)</h3>
									<p>Conducted an extensive literature review and benchmarking of monocular metric depth estimation (MMDE) models. Surveyed over 50 datasets and cataloged approximately 100 depth cameras to select the optimal hardware for research. Analyzed model limitations using custom-collected, multi-camera/resolution data across varying angles and distances. Presented findings on MMDE, including model performance on benchmark and proprietary datasets, to the entire research lab, establishing the groundwork for future depth estimation research.</p>

									<hr class="major" />
									<span style="float: right; color: grey;">April'24 - Nov'25</span>
									<h2>Undergraduate Researcher</h2>
									<h3 style ="float: right">Research advisor: Dr. Athira Nambiar</h3>
									<h3>SRM University, Chennai (<a href = "https://sites.google.com/view/aiforcomputervision">Centre for AI in Computer Vision Lab</a>)</h3>
									<p>Collaborated on the development of a novel, fully end-to-end architecture for event-based Visual Odometry (VO), moving beyond frame-based limitations by processing raw asynchronous events. I defined key technical components, including the transformer-based encoding for events and differentiable matching mechanism. Jointly implemented the training pipeline, conducted comprehensive cross-dataset testing (MVSEC, TUM-VIE, etc.), and co-authored the successful CVPR submission.</p>

									<hr class="major" />
									<span style="float: right; color: grey;">Nov'24 - March'25</span>
									<h2>Online Bachelor Intern</h2>
									<h3 style ="float: right">Internship advisor: Prof. Gang Li</h3>
									<h3>Deakin University, Victoria (<a href ="https://www.tulip.academy/members/gangli/">TULIP Lab</a>)</h3>
									<p>Worked on Computer Vision-based anomaly detection in manufacturing, analyzing benchmark datasets and training several Statistical and ML-based models. The best results were achieved with isolation-based models (iForest, iNN) trained on the diverse IPAD dataset, yielding a 99.1% AUROC (iForest). I also proposed an explainable system leveraging LSTM/LLM architectures for visual anomaly interpretation.</p>                                    
                                    
									<hr class="major" />
									<span style="float: right; color: grey;">May'24 - Jul'24</span>
									<h2>Summer Research Intern</h2>
									<h3 style ="float: right">Research advisor: Dr. Amit Agarwal</h3>
									<h3>Indian Institute of Technology, Roorkee (<a href = "https://faculty.iitr.ac.in/~amitfce/index.html#home">TSIM Lab - IITR</a>)</h3>
									<p>I understood the existing work behind the CrowdEye and TransitEye Entry-and-Exit counting systems - CrowdEye for dense religious places like Haridwar and TransitEye for public buses. The initial detection accuracy was very low, so I improved it to 92% on unseen scenes by training on new datasets (SCUTHead, CrowdHuman) and adding ROI-based counting to avoid false detections. I tuned hyperparameters to boost TransitEye performance. The main challenge in CrowdEye was speed: the model ran at 0.5 FPS, so I distilled YOLOv9e â†’ YOLOv9s, applied pruning, quantization, and OpenVINO optimisation, raising it to 30 FPS real-time on Raspberry Pi. I finally showcased the complete work at the IITR SPARK Poster Presentation Day 2024.</p>                                    
                                    
									<hr class="major" />
									<span style="float: right; color: grey;">May'25 - Jul'26</span>
									<h2>Online Project Intern</h2>
									<h3 style ="float: right">Project advisor: Dr. Sumathy G</h3>
									<h3><a href = "https://www.intel.in/content/www/in/en/corporate/unnati/industrial-training-program.html">Intel Unnati</a></h3>
									<p>I prepared and cleaned the Alpaca dataset, fine-tuned the Llama-2 model using Intel Developer Cloud, and optimized training with Intel Extension for Transformers. I then deployed the fine-tuned model as a Flask-based custom chatbot and built a simple PyQt5 desktop interface to demonstrate real inference and user interaction.</p>
								</section>

						</div>
					</div>

				
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<li><a href="education.html">Education</a></li>
										<li><a href="projects.html">Projects</a></li>
										<li><a href="achivements.html">Achievements</a></li>
										<li><a href="experience.html">Work Experience</a></li>
										<li><a href="certifications.html">Certifications</a></li>
									</ul>
								</nav>

								<section id="contact">
								<header class="major">
								<h2>Contact</h2>
								</header>
								Bhavisha Narendra Chaudhari </br>
								Personal mail: <a href = "mailto: bhavisha2705@gmail.com">bhavisha2705@gmail.com</a></br>
								University mail: <a href = "mailto: bc2780@srmist.edu.in">bc2780@srmist.edu.in</a></br>
        </section>
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
